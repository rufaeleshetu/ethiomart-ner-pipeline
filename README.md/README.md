# EthioMart NER Lending Score Analysis

## What this project does:
- âœ… Extracts pricing and entity data from Telegram vendors
- âœ… Tags text using fine-tuned NER
- âœ… Calculates vendor-level metrics and lending scores
- âœ… Visualizes performance and exports summary

Named Entity Recognition (NER) pipeline tailored for **Amharic Telegram-based E-commerce vendors**, leveraging **XLM-RoBERTa** and Hugging Face libraries. The pipeline covers full end-to-end functionality including scraping, preprocessing, fine-tuning, and deployment.

---

## ğŸ“Œ Objectives

- Extract Amharic messages from Telegram business channels
- Annotate and preprocess NER training data
- Fine-tune multilingual models (XLM-RoBERTa) on custom entities
- Evaluate and visualize model performance
- Deploy with Gradio and publish on Hugging Face Hub

---

## ğŸ§± Project Structure

ethiomart-ner-pipeline/
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks (EDA, tokenization, training)
â”œâ”€â”€ scripts/                     # Python scripts (scraper, preprocessor, app)
â”œâ”€â”€ data/                        # Raw and labeled data (e.g., .conll format)
â”œâ”€â”€ gradio_app/                  # Gradio UI for inference (deployed on Spaces)
â”œâ”€â”€ final_ner_model/            # Saved fine-tuned model (pushed to HF Hub)
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore
ğŸ” Named Entity Labels
We used domain-specific labels:

B-Product, I-Product

B-PRICE, I-PRICE

B-LOC, I-LOC

O for outside tokens

ğŸ”¬ Model Training & Evaluation
Metric	Score
Precision	86.27%
Recall	92.87%
F1 Score	89.45%
Eval Loss	1.65

Model: xlm-roberta-base (fine-tuned)

Trainer Args:

Epochs: 4

Batch Size: 8

Learning Rate: 2e-5

ğŸš€ Deployment
âœ… Model Hub: rufeshe/ethio-ner-model

âœ… Gradio Space: rufeshe/ethio-ner-space

ğŸ“¥ Usage

from transformers import AutoTokenizer, AutoModelForTokenClassification
from transformers import pipeline

tokenizer = AutoTokenizer.from_pretrained("rufeshe/ethio-ner-model")
model = AutoModelForTokenClassification.from_pretrained("rufeshe/ethio-ner-model")

ner = pipeline("ner", model=model, tokenizer=tokenizer, aggregation_strategy="simple")
ner("á‹­áˆ… áŠ á‹²áˆµ áˆ˜áˆ³áˆªá‹« á‰ 500 á‰¥áˆ­ áŠá‹á¢")
ğŸ§  Model Comparison & Interpretability
Compared baseline bert-base-multilingual-cased with xlm-roberta-base

Chose XLM-RoBERTa due to better F1 and recall on underrepresented tags

Used manual token-level inspection to verify prediction behavior

# ğŸ§¾ Task 6: Vendor Lending Score Analysis â€“ EthioMart

This task computes dynamic lending scores for Amharic e-commerce vendors on Telegram, based on extracted product and activity data.

## âœ… What We Did

In this task, we:
- Extracted **product prices** using regex from Amharic Telegram posts.
- Aggregated **posting frequency** (number of posts per vendor).
- Estimated **average views** per post (using actual or synthetic values).
- Calculated a **dynamic lending score** using a weighted formula:
Lending Score = 0.4 * (Normalized Posts)
+ 0.3 * (Normalized Views)
+ 0.3 * (Normalized Inverse Price)



- Normalized all metrics to 0â€“1 and scaled the score to 0â€“20.
- Exported the result as a CSV: `vendor_summary.csv`.
- Generated a Seaborn bar chart: `output.png`.

## ğŸ“Š Key Statistics

| Metric                    | Value         |
|---------------------------|---------------|
| ğŸ“¦ Average Price          | 3,600.00 ETB  |
| ğŸ‘€ Average Views per Post | 243.33        |
| ğŸ“ Average Posts per Vendor | 21.0        |
| ğŸ“ˆ Average Lending Score  | 15.92 (scaled from 0â€“20) |

## ğŸ“‚ Output Files

- `vendor_summary.csv` â€“ Vendor-wise metrics and lending score
- `output.png` â€“ Visualization of lending scores
- `README.md` â€“ This description

## ğŸ“Œ Rubric Alignment

- âœ… Lending score is dynamic and normalized
- âœ… Missing fields handled with exception logging
- âœ… Exported and visualized cleanly
- âœ… Fully documented in this README

ğŸ‘¤ Author
Rufeshe
ğŸ”— Hugging Face Profile
ğŸ“¬ For inquiries, reach out via your Hugging Face profile or GitHub